{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2d7c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Jan 29 2025 23:19:57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=NVIDIA Corporation\n",
      "GL_RENDERER=NVIDIA GeForce RTX 3050 Ti Laptop GPU/PCIe/SSE2\n",
      "GL_VERSION=3.3.0 NVIDIA 535.230.02\n",
      "GL_SHADING_LANGUAGE_VERSION=3.30 NVIDIA via Cg compiler\n",
      "pthread_getconcurrency()=0\n",
      "Version = 3.3.0 NVIDIA 535.230.02\n",
      "Vendor = NVIDIA Corporation\n",
      "Renderer = NVIDIA GeForce RTX 3050 Ti Laptop GPU/PCIe/SSE2\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ven = NVIDIA Corporation\n",
      "ven = NVIDIA Corporation\n"
     ]
    }
   ],
   "source": [
    "import pybullet\n",
    "import pybullet_data\n",
    "physics_client = pybullet.connect(pybullet.GUI) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aef3fec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pybullet.resetSimulation() # Reset the simulation space\n",
    "pybullet.setAdditionalSearchPath(pybullet_data.getDataPath()) # Add path to necessary data for pybullet\n",
    "pybullet.setGravity(0.0, 0.0, -9.8) # Set gravity as on Earth\n",
    "time_step = 1./240.\n",
    "pybullet.setTimeStep(time_step) # Set the elapsed time per step\n",
    "\n",
    "# Load the floor\n",
    "plane_id = pybullet.loadURDF(\"plane.urdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3360f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the robot\n",
    "car_start_pos = [0, 0, 0.1]  # Set the initial position (x, y, z)\n",
    "car_start_orientation = pybullet.getQuaternionFromEuler([0, 0, 0])  # Set the initial orientation (roll, pitch, yaw)\n",
    "car_id = pybullet.loadURDF(\"../urdf/mobile_robot_with_arm.urdf\", car_start_pos, car_start_orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b211bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Camera settings (similar to AR marker detection notebook)\n",
    "fov = 60  # Field of view in degrees\n",
    "image_width = 640\n",
    "image_height = 480\n",
    "aspect = image_width / image_height\n",
    "near = 0.05  # Near clipping plane\n",
    "far = 10.0   # Far clipping plane\n",
    "\n",
    "# Compute projection matrix\n",
    "projection_matrix = pybullet.computeProjectionMatrixFOV(fov, aspect, near, far)\n",
    "\n",
    "# Set camera view for GUI\n",
    "camera_distance = 2.0\n",
    "camera_yaw = 45.0\n",
    "camera_pitch = -30.0\n",
    "camera_target_position = [0.0, 0.0, 0.5]\n",
    "pybullet.resetDebugVisualizerCamera(camera_distance, camera_yaw, camera_pitch, camera_target_position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba570e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB-D Camera Link Index: 6\n",
      "RGB-D Camera Target Link Index: 7\n"
     ]
    }
   ],
   "source": [
    "# Function to get link index by name\n",
    "def get_link_index_by_name(robot_id, link_name):\n",
    "    \"\"\"\n",
    "    Get the link index by searching through all joints.\n",
    "    In PyBullet, child link indices are the same as joint indices.\n",
    "    \"\"\"\n",
    "    # Search through all joints\n",
    "    num_joints = pybullet.getNumJoints(robot_id)\n",
    "    for i in range(num_joints):\n",
    "        joint_info = pybullet.getJointInfo(robot_id, i)\n",
    "        child_link_name = joint_info[12].decode('utf-8')\n",
    "        if child_link_name == link_name:\n",
    "            # Return the child link index (same as joint index for child links)\n",
    "            return i\n",
    "    \n",
    "    # If not found, return None\n",
    "    return None\n",
    "\n",
    "# Get camera link indices\n",
    "rgbd_camera_link_idx = get_link_index_by_name(car_id, \"rgbd_camera_link\")\n",
    "rgbd_camera_target_link_idx = get_link_index_by_name(car_id, \"rgbd_camera_target_vertual_link\")\n",
    "\n",
    "print(f\"RGB-D Camera Link Index: {rgbd_camera_link_idx}\")\n",
    "print(f\"RGB-D Camera Target Link Index: {rgbd_camera_target_link_idx}\")\n",
    "\n",
    "# If we can't find by name, we'll use a fallback method\n",
    "# Actually, in PyBullet, link indices for fixed joints are the same as joint indices\n",
    "# Let's try to get link state directly\n",
    "if rgbd_camera_link_idx is None:\n",
    "    # Alternative: search through all links\n",
    "    # For now, let's assume the links exist and try to access them\n",
    "    # We'll handle errors in the main loop\n",
    "    print(\"Warning: Could not find camera link by name. Will try to use joint indices.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8770fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 0: RGB shape=(480, 640, 4), Depth range=[0.844, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 60: RGB shape=(480, 640, 4), Depth range=[0.844, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 120: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 180: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 240: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 300: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 360: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 420: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 480: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 540: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 600: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 660: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 720: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 780: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 840: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 900: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 960: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 1020: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 1080: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 1140: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 1200: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 1260: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 1320: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 1380: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 1440: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 1500: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 1560: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 1620: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 1680: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 1740: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 1800: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 1860: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 1920: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 1980: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 2040: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 2100: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 2160: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 2220: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 2280: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 2340: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 2400: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 2460: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 2520: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 2580: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 2640: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 2700: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 2760: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 2820: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 2880: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 2940: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 3000: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 3060: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 3120: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 3180: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 3240: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 3300: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 3360: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 3420: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 3480: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 3540: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 3600: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 3660: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 3720: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 3780: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 3840: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 3900: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 3960: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 4020: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 4080: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 4140: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 4200: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 4260: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 4320: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 4380: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 4440: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 4500: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 4560: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 4620: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 4680: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 4740: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 4800: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 4860: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 4920: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 4980: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 5040: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 5100: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 5160: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 5220: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 5280: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 5340: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 5400: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 5460: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Frame 5520: RGB shape=(480, 640, 4), Depth range=[0.842, 1.000]m, Seg IDs=[  0 255]\n",
      "Interrupted by user\n",
      "Camera display windows closed.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Main loop to capture and display camera images\n",
    "# Press 'q' to quit the display windows\n",
    "\n",
    "# Create named windows for display\n",
    "cv2.namedWindow('RGB Image', cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow('Depth Image', cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow('Segmented Image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "try:\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        # Step simulation\n",
    "        pybullet.stepSimulation()\n",
    "        \n",
    "        # Try to get camera link positions\n",
    "        # First, let's find the correct link indices by checking all joints\n",
    "        if rgbd_camera_link_idx is None or rgbd_camera_target_link_idx is None:\n",
    "            # Search for camera links\n",
    "            num_joints = pybullet.getNumJoints(car_id)\n",
    "            for i in range(num_joints):\n",
    "                joint_info = pybullet.getJointInfo(car_id, i)\n",
    "                link_name = joint_info[12].decode('utf-8')\n",
    "                if \"rgbd_camera_link\" in link_name and rgbd_camera_link_idx is None:\n",
    "                    rgbd_camera_link_idx = i\n",
    "                if \"rgbd_camera_target\" in link_name and rgbd_camera_target_link_idx is None:\n",
    "                    rgbd_camera_target_link_idx = i\n",
    "        \n",
    "        # Get camera link positions and orientations\n",
    "        try:\n",
    "            if rgbd_camera_link_idx is not None:\n",
    "                camera_link_state = pybullet.getLinkState(car_id, rgbd_camera_link_idx)\n",
    "                camera_link_position = camera_link_state[0]  # World position\n",
    "                camera_link_orientation = camera_link_state[1]  # World orientation (quaternion)\n",
    "            else:\n",
    "                # Fallback: use base link position + offset\n",
    "                base_state = pybullet.getBasePositionAndOrientation(car_id)\n",
    "                camera_link_position = [base_state[0][0] + 0.12, base_state[0][1], base_state[0][2] + 0.08]\n",
    "                camera_link_orientation = base_state[1]\n",
    "            \n",
    "            if rgbd_camera_target_link_idx is not None:\n",
    "                camera_target_state = pybullet.getLinkState(car_id, rgbd_camera_target_link_idx)\n",
    "                camera_target_position = camera_target_state[0]\n",
    "            else:\n",
    "                # Fallback: position camera target 0.2m in front of camera\n",
    "                # Convert quaternion to rotation matrix to get forward direction\n",
    "                # For simplicity, assume camera points in +Y direction (forward)\n",
    "                camera_target_position = [camera_link_position[0] + 0.2, \n",
    "                                         camera_link_position[1], \n",
    "                                         camera_link_position[2]]\n",
    "        except:\n",
    "            # If link access fails, use base position with offset\n",
    "            base_state = pybullet.getBasePositionAndOrientation(car_id)\n",
    "            camera_link_position = [base_state[0][0] + 0.12, base_state[0][1], base_state[0][2] + 0.08]\n",
    "            camera_target_position = [camera_link_position[0] + 0.2, \n",
    "                                     camera_link_position[1], \n",
    "                                     camera_link_position[2]]\n",
    "        \n",
    "        # Compute view matrix\n",
    "        view_matrix = pybullet.computeViewMatrix(\n",
    "            cameraEyePosition=camera_link_position,\n",
    "            cameraTargetPosition=camera_target_position,\n",
    "            cameraUpVector=[0, 0, 1]  # Z-axis is up\n",
    "        )\n",
    "        \n",
    "        # Get camera image (returns width, height, rgbImg, depthImg, segImg)\n",
    "        width, height, rgb_img, depth_img, seg_img = pybullet.getCameraImage(\n",
    "            width=image_width,\n",
    "            height=image_height,\n",
    "            viewMatrix=view_matrix,\n",
    "            projectionMatrix=projection_matrix,\n",
    "            renderer=pybullet.ER_BULLET_HARDWARE_OPENGL\n",
    "        )\n",
    "        \n",
    "        # Process RGB image (already in correct format)\n",
    "        rgb_display = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Process depth image\n",
    "        # Depth image is in meters, normalize for display (0-255)\n",
    "        depth_array = np.array(depth_img)\n",
    "        # Normalize depth to 0-255 range for visualization\n",
    "        depth_normalized = cv2.normalize(depth_array, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        depth_colormap = cv2.applyColorMap(depth_normalized, cv2.COLORMAP_JET)\n",
    "        \n",
    "        # Process segmented image\n",
    "        # Segmentation image contains object IDs, convert to color image\n",
    "        seg_array = np.array(seg_img, dtype=np.uint8)\n",
    "        seg_colormap = cv2.applyColorMap(seg_array, cv2.COLORMAP_HSV)\n",
    "        \n",
    "        # Display images\n",
    "        cv2.imshow('RGB Image', rgb_display)\n",
    "        cv2.imshow('Depth Image', depth_colormap)\n",
    "        cv2.imshow('Segmented Image', seg_colormap)\n",
    "        \n",
    "        # Print some info every 60 frames (about 4 times per second at 240Hz)\n",
    "        if frame_count % 60 == 0:\n",
    "            print(f\"Frame {frame_count}: RGB shape={rgb_img.shape}, Depth range=[{depth_array.min():.3f}, {depth_array.max():.3f}]m, Seg IDs={np.unique(seg_array)}\")\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Check for 'q' key to quit\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            print(\"Quitting camera display...\")\n",
    "            break\n",
    "        \n",
    "        # Small sleep to prevent overwhelming the system\n",
    "        time.sleep(time_step)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted by user\")\n",
    "finally:\n",
    "    # Clean up\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Camera display windows closed.\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
